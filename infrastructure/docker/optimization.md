# Ресурсы и оптимизация

## Зачем ограничивать ресурсы контейнеров

По умолчанию контейнер в Linux имеет доступ ко всем CPU и практически всей памяти хоста.
Если один сервис начинает «съедать» ресурсы, он может положить не только соседние контейнеры, но и весь сервер, что для backend‑системы часто неприемлемо.

Лимиты ресурсов позволяют:

- изолировать шумных соседей;
- делать поведение системы более предсказуемым;
- выявлять ошибки (утечки памяти, бесконечные циклы) на ранних этапах;
- уверенно запускать несколько сервисов на одном хосте.

---

## Лимиты памяти: что происходит при OOM

Память — самый чувствительный ресурс.
Если контейнер выходит за пределы доступной памяти, ядро может:

- убить процесс внутри контейнера (OOM‑killer);
- повлиять на другие процессы на хосте, если лимитов нет вовсе.

Docker поддерживает два основных типа ограничений:

- жёсткий лимит (hard limit) — контейнер не может использовать больше заданного объёма;
- «мягкий» лимит (reservation) — желаемый уровень потребления, при котором система начинает применять давление, но не сразу убивает контейнер.

Примеры запуска:

```sh
# Жёсткий лимит 512МБ
docker run -m 512m --memory-swap 512m my-api:latest

# Мягкий лимит 256МБ, жёсткий 512МБ
docker run -m 512m --memory-reservation 256m my-api:latest
```

Типичные эффекты для backend‑сервиса:

- при слишком маленьком лимите GC (в Go, JVM и др.) начинает работать агрессивно, вызывая паузы и падение throughput;
- при утечке памяти контейнер будет регулярно умирать по OOM, что хорошо видно по логам и событиям оркестратора;
- при отсутствии лимитов один «слетевший» сервис способен съесть всю память и уронить весь хост.

---

## Лимиты CPU: доли, квоты, affinity

CPU в Docker регулируется более гибко, чем память.
Цель лимитов по CPU — не столько «жёстко запретить», сколько справедливо поделить вычислительную мощность между сервисами.

Основные опции:

- `--cpus` — простое ограничение суммарной доли CPU;
- `--cpu-shares` — относительный приоритет (soft limit: учитывается при конкуренции);
- `--cpu-quota` + `--cpu-period` — тонкий контроль по CFS‑квотам;
- `--cpuset-cpus` — pin’инг контейнера к конкретным ядрам.

Примеры:

```sh
# Не больше полутора CPU
docker run --cpus="1.5" my-api:latest

# Дать контейнеру больший приоритет по сравнению с другими
docker run --cpu-shares=2048 my-critical-service:latest

# Жёстко ограничить 50% одного ядра
docker run --cpu-period=100000 --cpu-quota=50000 my-db:latest

# Привязать к ядрам 0 и 1 (важно для latency-чувствительных сервисов)
docker run --cpuset-cpus="0,1" my-api:latest
```

Для backend‑сервисов обычно достаточно:

- простого `--cpus` для ограничения «верхнего потолка»;
- `--cpu-shares` для приоритизации критичных сервисов при конкуренции.

---

## Лимиты PIDs (количество процессов/тредов)

Контейнер может создавать большое количество процессов и тредов: worker‑пулы, fork’и, сторонние утилиты и т.п.
Без ограничений runaway‑процесс легко «съедает» все PID на хосте, приводя к отказу других сервисов.

Контроль количества процессов осуществляется через `--pids-limit`:

```sh
# Не больше 512 процессов/тредов внутри контейнера
docker run --pids-limit=512 my-api:latest
```

Эффекты для backend‑приложения:

- защита от багов, которые создают тысячи тредов;
- явный сигнал при выходе за лимит (ошибки при создании новых процессов/тредов);
- необходимость осознавать, сколько тредов в норме создаёт приложение (Go runtime, пул БД, worker‑ы).

Для обычного HTTP‑API зачастую достаточно лимита в несколько сотен PIDs, для тяжёлых JVM‑систем и брокеров — больше.

---

## Как лимиты влияют на backend‑сервисы

### Слишком жёсткие лимиты

Симптомы:

- рост latency;
- частые рестарты контейнеров по OOM или по сигналу от оркестратора;
- агрессивный GC, «ступенчатый» throughput.

Причины:

- ограничение памяти ниже реально используемого объёма;
- ограничение CPU вызывает постоянный throttling под нагрузкой.

### Слишком мягкие или отсутствующие лимиты

Симптомы:

- один сервис под высокой нагрузкой «топит» соседей;
- деградация всего хоста при нагрузке на один контейнер;
- непредсказуемое поведение при пиках трафика.

Причины:

- отсутствие политики ресурсных ограничений;
- запуск тяжёлых фоновых задач в тех же контейнерах, что и онлайн‑трафик.

---

## Практический подход к выбору лимитов

1. **Сначала измерить.**
   Запустить сервис без жёстких лимитов в контролируемой среде, собрать метрики CPU/Memory под типичной и пиковой нагрузкой.

2. **Выбрать стартовые значения.**
   Например:
   – memory limit ≈ 2× пикового потребления;
   – CPU limit — чуть выше средних пиков (например, 1.5–2 CPU на сервис).

3. **Добавить мониторинг и алерты.**
   Следить за отношением `usage / limit`, количеством OOM и throttling (для CPU).

4. **Итеративно корректировать.**
   Если usage стабильно ниже 30–40% от лимита — лимит можно снизить, освобождая ресурсы.
   Если usage стабильно на уровне 80–90% и есть жалобы на latency — лимит стоит поднять или оптимизировать код.

---

## Ресурсные лимиты в Docker Compose

В Compose (v3+) лимиты задаются через секцию `deploy.resources` (активно в Swarm‑режиме) или на уровне конкретной среды/оркестратора.

Пример:

```sh
services:
  api:
    image: my-api:1.0.0
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 512M
        reservations:
          cpus: "0.25"
          memory: 256M
```

Даже если локально эти поля могут не применяться, хранить их в конфигурации полезно:

- как документацию ожиданий по ресурсам;
- как часть спецификации для оркестрации (Swarm, ECS и т.п.).

---

## Резюме

Контроль ресурсов контейнеров — обязательная практика для серьёзных backend‑систем.
Грамотные лимиты по памяти, CPU и PIDs помогают построить предсказуемое и защищённое окружение, в котором один сервис не может легко «унитожить» соседей, а проблемы с производительностью проявляются в виде явных сигналов, а не внезапных падений всего кластера.


## Задача: не только ограничивать, но и ускорять

Лимиты ресурсов задают «рамки», внутри которых сервис живёт.
Но в этих рамках его можно сделать как медленным и тяжёлым, так и быстрым и эффективным.

Оптимизация Docker‑окружения включает в себя:

- работу с файловой системой (overlay2, слои образов, кеширование);
- I/O‑паттерны (random vs sequential, bind‑mount vs volume);
- использование tmpfs для временных данных;
- сетевые настройки и паттерны доступа;
- организацию сборки образов.

---

## Файловая система и overlay2

Современные Docker‑демоны на Linux по умолчанию используют драйвер `overlay2`.
Он реализует copy‑on‑write поверх слоёв образа: каждый новый слой добавляет свои файлы, не копируя предыдущие.

Эффекты:

- чтение из нижних слоёв обычно быстрое;
- запись может быть дороже (copy‑up), особенно при частой модификации больших файлов;
- количество слоёв и их структура существенно влияют на скорость сборки и размер образа.

### Рекомендации

- минимизировать количество слоёв, которые активно пишут данные;
- избегать сценариев, где приложение постоянно переписывает одни и те же большие файлы внутри контейнера;
- для активных write‑heavy каталогов использовать тома или tmpfs.

---

## Кэш слоёв образа и ускорение сборки

Сборка Docker‑образов сильно завязана на порядок инструкций в Dockerfile.
Каждая инструкция создаёт слой, и если предыдущие слои не изменились, Docker переиспользует кеш.

Плохой пример:

```sh
FROM golang:1.23

COPY . /app
WORKDIR /app
RUN go build -o /bin/app ./cmd/app
```

Любое изменение в коде инвалидирует кеш для всего, что после `COPY .`.

Лучший подход:

```sh
FROM golang:1.23 AS builder

WORKDIR /app

# Сначала зависимости
COPY go.mod go.sum ./
RUN go mod download

# Затем код
COPY . .
RUN go build -o /bin/app ./cmd/app

FROM gcr.io/distroless/base-debian12
COPY --from=builder /bin/app /bin/app
ENTRYPOINT ["/bin/app"]
```

Преимущества:

- при небольших изменениях в коде зависимости подтягиваются из кеша;
- финальный образ небольшой (distroless), меньше поверхност атаки и быстрее доставляется по сети;
- чётко отделены «статичные» и «изменчивые» слои.

---

## I/O: volumes против bind‑mount

Не все способы хранения данных внутри контейнера одинаковы с точки зрения производительности.

### Именованные тома (volumes)

- создаются и управляются Docker’ом;
- обычно дают лучшую производительность, чем bind‑mount, особенно на Linux;
- оптимальны для БД, кешей и других write‑heavy сервисов.

Пример:

```sh
services:
  postgres:
    image: postgres:16
    volumes:
      - postgres_data:/var/lib/postgresql/data

volumes:
  postgres_data:
```

### Bind‑mount (каталоги хоста)

- монтируют реальную файловую систему хоста;
- удобны для разработки (код, конфиги, лог‑директории);
- могут быть медленнее, особенно на macOS/Windows (Docker Desktop + VM).

Для прод‑подобной нагрузки write‑heavy данные лучше хранить в томах, а не в bind‑mount.

---

## tmpfs для временных данных

Временные файлы и кеши, которые не нужно сохранять, могут жить в памяти.
Docker позволяет монтировать tmpfs:

```
docker run \
  --tmpfs /tmp \
  --tmpfs /cache \
  my-api:latest
```

Эффекты:

- быстрый I/O (операции идут в память);
- отсутствие износа диска и «шума» в файловой системе;
- данные исчезают при перезапуске контейнера (что для temp‑данных — плюс).

Для backend‑приложений tmpfs может быть полезен для:

- временных файлов, генерируемых при обработке запросов;
- промежуточных артефактов (архивы, отчёты, буферы).

Нужно помнить о расходе памяти: tmpfs отнимает RAM, и лимиты памяти контейнера должны это учитывать.

---

## Network tuning

Сетевые накладные расходы действительно есть, но чаще bottleneck’ом становится приложение или внешняя система (БД, внешний API), а не сам Docker.
Тем не менее, некоторые настройки и паттерны могут заметно помочь.

### Выбор сетевого драйвера

- `bridge` — разумный дефолт;
- `host` — минимум overhead’а (нет NAT, нет виртуального интерфейса), но и минимальная изоляция.

Для latency‑чувствительных сервисов, которые работают только на выделенном хосте и строго контролируются, `--network host` может дать выигрыш в микросекундах/миллисекундах.
Однако в большинстве случаев выигрыш невелик по сравнению с усложнением безопасности и конфигурации.

### Соединения внутри одного хоста

При взаимодействии контейнеров на одном хосте:

- использовать DNS‑имена (сервисов) вместо IP, но не гонять трафик через лишние прокси без необходимости;
- при большом количестве соединений (например, high‑QPS gRPC) убедиться, что количество соединений и keep‑alive настройки оптимизированы на уровне приложения.

---

## Ограничение логов и их формат

Логирование — скрытый источник деградации производительности.

Проблемы:

- синхронная запись больших объёмов логов на диск;
- формат, требующий тяжёлой сериализации (слишком подробный JSON, большие stack trace);
- отсутствие ротации.

Рекомендации:

- переключать лог‑драйвер или отправлять логи в stdout, а уже с хоста собирать их агентом (Fluent Bit, Vector и т.п.);
- ограничивать уровень логирования в проде (уменьшать DEBUG, оставлять INFO/WARN/ERROR);
- ротация и ограничение размеров лог‑файлов, если используется файловый драйвер.

В Docker‑контейнерах иногда полезно монтировать отдельный том под логи и управлять ими независимо от остальной файловой системы.

---

## Наблюдаемость и измерения

Настройка ограничений и оптимизаций без измерений напоминает слепую стрельбу.
Для серьёзной настройки производительности необходимы:

- метрики CPU/Memory/Network/Disk per container (Prometheus + cAdvisor, интеграция с runtime приложений);
- профилирование приложения (pprof для Go, APM‑агенты и т.п.);
- наблюдение за временем отклика и ошибками (SLO/SLA).

Сценарий:

1. Нагрузочное тестирование с реальными паттернами трафика.
2. Сбор метрик до применения оптимизаций.
3. Изменение конфигурации Docker (лимиты, тома, сети, Dockerfile).
4. Повтор теста и сравнение показателей.

---

## Практические чеклисты

### Перед запуском в прод‑подобное окружение

- Образ минимален по размеру, слои логично упорядочены.
- БД и кеш используют именованные тома.
- Временные файлы (если они значимы) вынесены в tmpfs или отдельный том.
- Лимиты CPU/Memory/PIDs заданы и задокументированы.
- Логи не пишутся бездумно в «толстые» файлы на overlay2.

### При расследовании проблем производительности

- Проверить `docker stats` / метрики оркестрации: есть ли throttling по CPU, как близко использование памяти к лимитам.
- Оценить I/O: не лежит ли Postgres/Redis на медленном диске или bind‑mount через Docker Desktop.
- Проверить, не перегружен ли слой логирования.
- Убедиться, что приложение оптимизировано хотя бы базово (пулы соединений, кеши, профилирование).

---

## Заключение

Docker не делает приложение ни «по умолчанию медленным», ни «по умолчанию быстрым».
Он создаёт абстракцию, внутри которой можно как убить производительность неправильной конфигурацией, так и выжать из железа максимум.

Понимание лимитов ресурсов, поведения файловой системы, особенностей I/O и сетевых паттернов — обязательная часть инженерной культуры backend‑разработчика, работающего с контейнерами.
Остальное — дисциплина измерений, чёткие SLO и готовность регулярно возвращаться к настройкам, когда меняется нагрузка и архитектура.
