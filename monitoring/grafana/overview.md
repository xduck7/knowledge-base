# Grafana: обзор и место в стеке наблюдаемости

Grafana — это платформа визуализации и анализа данных, которая умеет подключаться к разным источникам (метрики, логи, трейсы, БД) и показывать их в виде интерактивных дашбордов.  
Её основная задача — помочь понять, что происходит с системой: от инфраструктуры и бэкенд‑сервисов до бизнес‑метрик.

## Зачем нужна Grafana

Практически любая продовая система рано или поздно приходит к вопросу наблюдаемости: нужно видеть загрузку ресурсов, ошибок, задержки, бизнес‑показатели и вовремя реагировать на деградации.  
Grafana отвечает именно за «человеческий» слой — за визуализацию и удобный доступ к этим данным.

Типичные задачи:

- мониторинг бэкенд‑сервисов: RPS, latency, ошибки, нагрузка на БД и кеши;  
- мониторинг инфраструктуры: хосты, контейнеры, Kubernetes, очереди, балансировщики;  
- анализ инцидентов: что случилось, когда началось, какие компоненты задеты;  
- продуктовая аналитика на уже готовых данных (из БД/аналитического хранилища).

Важно понимать, что Grafana сама по себе не «собирает» и не «хранит» данные.  
Она читает их из других систем (Prometheus, Loki, Tempo, Elasticsearch, PostgreSQL и т.д.) и строит поверх этого дашборды, графики и алерты.

## Типовые сценарии: кто и как использует Grafana

### SRE/DevOps

Для SRE и DevOps Grafana — основной UI к стэку мониторинга и логирования.  
Через неё смотрят:

- общие дашборды инфраструктуры (кластера, хосты, сети, диски);  
- состояние Kubernetes (нагрузка по нодам, pod’ы, ошибки, restarts, pending);  
- SLA/SLO (аптайм, error budget).

Часто на больших мониторах в офисе висят «обзорные» дашборды, которые показывают состояние всей платформы в реальном времени.

### Backend‑разработчики

Для бэкенд‑разработчика Grafana — инструмент, который показывает здоровье конкретного сервиса.  
Обычно для каждого важного сервиса есть свой дашборд с:

- RPS, распределением по endpoint’ам, статус‑кодам;  
- latency (p50/p95/p99), таймауты, ретраи;  
- ошибками (5xx/4xx, business‑ошибки);  
- зависимостями: БД, кеш, очереди, внешние API.

### Продукт / аналитики / бизнес

Grafana всё чаще используется не только для технарей.  
Если к ней подключена аналитическая БД (PostgreSQL, ClickHouse, BigQuery и т.п.):

- строят BI‑дашборды без полноценной BI‑системы;  
- показывают конверсию, выручку, поведение пользователей;  
- дают менеджерам живую картинку по продукту.

В этом сценарии Grafana конкурирует уже не с Prometheus, а с Power BI, Tableau, Metabase и т.п.

### Support / NOC

Для служб поддержки и NOC (Network Operations Center) Grafana — это большие экраны, на которых:

- крупно показаны ключевые SLO/SLA;  
- выделяются красным критические алерты;  
- визуализируются географические/региональные проблемы (карты, heatmap’ы).

Задача — быстро понять, что «горит», не залезая глубоко в технические детали.

## Как Grafana вписывается в стек наблюдаемости

В типичном backend‑стеке наблюдаемости роли примерно такие:

- Prometheus (или аналог) — собирает и хранит метрики;  
- Loki / Elasticsearch / OpenSearch — хранят и ищут логи;  
- Tempo / Jaeger / Zipkin — хранят распределённые трейсы;  
- Grafana — визуализирует всё это и связывает между собой.

Примеры связок:

- **Prometheus + Grafana** — метрики инфраструктуры и приложений;  
- **Loki + Grafana** — просмотр и фильтрация логов;  
- **Tempo + Grafana** — распределённые трейсы: путь запроса через микросервисы;  
- **PostgreSQL + Grafana** — бизнес‑дашборды по данным из БД.

Grafana не заменяет системы сбора данных, а сидит поверх них — как «единое окно» для всех типов сигнала: метрики, логи, трейсы, события.

## Архитектура Grafana на высоком уровне

На простом уровне Grafana — это веб‑приложение, у которого есть:

- frontend (Web UI, на котором пользователи смотрят и редактируют дашборды);  
- backend (HTTP API, логика авторизации, работа с БД и datasource’ами);  
- база данных конфигурации (SQLite/PostgreSQL/MySQL);  
- набор плагинов (datasource’ы, типы панелей, алерты и т.д.).

### Источники данных (datasources)

Datasource — это абстракция «как и откуда Grafana получает данные».  
Каждый datasource знает:

- как подключиться (URL, креды, TLS, параметры);  
- как выглядят запросы (PromQL, Loki Query Language, SQL, Elasticsearch Query DSL и т.д.);  
- как интерпретировать ответ.

Типичные datasources:

- Prometheus (метрики);  
- Loki (логи);  
- Tempo (трейсы);  
- PostgreSQL/MySQL/ClickHouse и другие SQL‑БД;  
- Elasticsearch / OpenSearch;  
- Cloud‑провайдеры (CloudWatch, Azure Monitor, GCP Monitoring и т.д.).

### Дашборды и панели

**Dashboard** — это набор панелей и общих настроек (тайм‑диапазон, переменные, теги), объединённых в один экран.  
Обычно дашборды группируют по сервисам, командам, продуктам или окружениям (dev/stage/prod).

**Panel** — это одна визуализация:

- график (time series);  
- таблица;  
- stat (одно число с трендом);  
- gauge, bar chart, heatmap, pie и т.д.

Каждая панель использует один или несколько запросов к datasource’ам, задаёт формат отображения, цвета, пороги, агрегаты.

### Алерты и уведомления

Современная Grafana умеет алертинг «внутри себя» (Alerting Unified):

- alert rule описывает условие (`если latency p95 > X в течение Y минут`);  
- contact point определяет, куда слать (email, Slack, Telegram, webhook, PagerDuty и т.д.);  
- notification policy описывает маршрутизацию по severity, сервисам, тегам.

При этом сами запросы к данным делаются через те же datasources: Grafana регулярно выполняет запрос и проверяет, выполняется ли условие алерта.

### Организации, папки, команды

Для структурирования и прав доступа используются:

- **Organization** — верхний уровень (иногда одна на всю компанию, иногда несколько);  
- **Folder** — логическая папка дашбордов (по продукту, по команде, по окружению);  
- **Team / User Roles** — группы пользователей и роли (Viewer, Editor, Admin).

Это позволяет:

- дать одной команде полный доступ к своим дашбордам;  
- дать только чтение менеджерам;  
- изолировать разные проекты внутри одной инсталляции Grafana.

---

# Установка и развертывание Grafana

В этом разделе — практическое руководство, как поднять Grafana в разных сценариях: локально в Docker, в Kubernetes и на обычной машине.  
Фокус на том, как сделать это production‑friendly: хранение состояния, обновления, бэкапы, конфиг как код.

## Варианты развертывания

Основные варианты:

- Docker / Docker Compose — быстрое локальное развёртывание и небольшие стендалон‑инсталляции;  
- Kubernetes (обычно через Helm) — стандарт для средних и крупных компаний;  
- Bare‑metal / VM — установка через пакеты или архив, полезна там, где нет контейнеров.

### Docker

Для большинства сценариев «попробовать Grafana» или «маленькая команда» Docker — самый простой путь.  
Шаги:

1. Скачивается официальный образ Grafana.  
2. Запускается контейнер с пробросом порта 3000 и volume для данных.  
3. В браузере по `http://localhost:3000` открывается UI; дефолтный логин/пароль — `admin` / `admin` (обязательно поменять).

### Kubernetes

В Kubernetes обычно используют официальный Helm‑чарт:

- описываются все настройки в `values.yaml`;  
- деплой делается через `helm upgrade --install`;  
- Grafana живёт в отдельном namespace (часто `observability` или `monitoring`).

Это удобный способ:

- версионировать конфигурацию Grafana;  
- легко обновлять версию;  
- вписать Grafana в общую GitOps‑цепочку.

### Bare‑metal / VM

Иногда инфраструктура ещё не контейнеризирована — тогда Grafana ставится как обычное приложение:

- через пакеты (например, `apt`/`yum`) или tar‑архив;  
- поднимается systemd unit;  
- конфиг пишется в `/etc/grafana/grafana.ini`, данные лежат в `/var/lib/grafana`.

Такой вариант проще для небольших инсталляций, но усложняет переносимость и автоматизацию по сравнению с Kubernetes/Docker.

## Конфигурация и хранение состояния

У Grafana есть два ключевых слоя состояния:

1. **Конфигурация приложения** (настройки сервера, аутентификации, путей и т.п.);  
2. **Данные Grafana** (пользователи, дашборды, datasources, алерты и т.д.), которые лежат в БД.

### Конфигурационный файл `grafana.ini`

Базовый конфигурационный файл:

- по умолчанию называется `grafana.ini`;  
- содержит секции (`[server]`, `[security]`, `[auth]`, `[database]`, `[dashboards]`, `[alerting]` и т.д.);  
- позволяет настроить порт, базовый URL, аутентификацию, БД, e‑mail, логирование.

В контейнеризованных окружениях настройки часто переопределяют через переменные окружения:

- вместо правки `grafana.ini` задаются env’ы вида `GF_SERVER_ROOT_URL`, `GF_SECURITY_ADMIN_USER` и т.д.;  
- это удобно для Kubernetes и Docker Compose.

### База данных Grafana

Grafana хранит своё состояние в реляционной БД.  
Поддерживаются:

- SQLite (используется по умолчанию);  
- PostgreSQL;  
- MySQL / MariaDB.

В БД лежит:

- список пользователей, ролей, команд, организаций;  
- дашборды (в JSON‑формате), папки, теги;  
- источники данных (datasources) и их настройки;  
- правила алертинга, contact points, notification policies и т.д.

Для прод‑окружений обычно рекомендуют PostgreSQL или MySQL:

- это даёт лучшую надёжность и удобство бэкапов;  
- упрощает горизонтальное масштабирование (несколько реплик Grafana, общая БД).

SQLite оправдана для:

- локальной разработки;  
- очень маленьких дэшей/команд;  
- временных стендов.

## Развёртывание через Docker: практический минимум

Простейший запуск может выглядеть так (упрощённо):

```sh
docker run -d \
  -p 3000:3000 \
  --name=grafana \
  -e GF_SECURITY_ADMIN_USER=admin \
  -e GF_SECURITY_ADMIN_PASSWORD=change_me \
  -v grafana-data:/var/lib/grafana \
  grafana/grafana-oss:latest
```

Ключевые моменты:

- порт 3000 проброшен наружу;  
- данные (`/var/lib/grafana`) вынесены в volume, чтобы не потерять их при пересоздании контейнера;  
- админ‑логин и пароль задаются через env (в проде дефолт `admin/admin` использовать нельзя).

Через `docker-compose` можно описать это в yaml и версионировать вместе с кодом/инфрой.

## Развёртывание в Kubernetes через Helm

Типичный подход:

1. Определяется namespace (например, `observability`).  
2. Готовится `values.yaml` с нужными настройками:  
   - ресурсы (CPU/memory);  
   - persistent volume;  
   - ingress (доступ извне, TLS);  
   - admin‑учётка, дополнительные env’ы;  
   - включение/отключение встроенного алертинга.  
3. Выполняется установка/обновление релиза через Helm.

Преимущества:

- единая точка правды — `values.yaml` в Git;  
- лёгкое обновление версии Grafana;  
- интеграция с остальными компонентами (Prometheus, Loki, Tempo) в кластере.

## Конфиг как код и provisioning

Для production‑подхода важно, чтобы:

- datasources, дашборды и алерты не создавались только руками через UI;  
- была возможность быстро восстановить Grafana или поднять её копию (dev/stage).

Grafana поддерживает provisioning:

- отдельные yaml‑файлы для datasources, в которых описаны все подключения;  
- yaml‑файлы для дашбордов (указание директорий с JSON‑дашбордами, папок, org’ов);  
- конфигурация алертинга и notification channels.

Обычно:

- эти файлы хранятся в Git‑репозитории;  
- при деплое (Docker/K8s/Ansible) они попадают на диск Grafana;  
- при старте Grafana автоматически подхватывает и применяет их.

Такой подход упрощает:

- код‑ревью изменений дашбордов и datasources;  
- перенос дашбордов между окружениями (dev → stage → prod);  
- восстановление после инцидента.

## Обновления и миграции

Обновление Grafana — это всегда баланс между новыми фичами и риском поломать совместимость:

- каждая версия приносит новые возможности (новые типы панелей, улучшения алертинга, security‑фиксы);  
- иногда меняется формат хранения данных или API.

Практичный процесс:

1. Читать release notes, особенно разделы breaking changes.  
2. Прогонять обновление сначала в dev/stage окружении с копией конфигурации.  
3. Делать бэкап БД (и, на всякий случай, конфигов/provisioning) перед обновлением продовой Grafana.  
4. Иметь план отката (downgrade образа/пакета + восстановление БД).

### Миграция хранилища (например, SQLite → PostgreSQL)

Типичный сценарий:

- на старте всё крутится на SQLite;  
- со временем вырастают нагрузки и требуется перенести состояние в PostgreSQL.

Подход:

- развернуть новый экземпляр БД (PostgreSQL/MySQL);  
- выполнить миграцию данных (через утилиты, дамп/restore, штатные инструменты);  
- обновить конфиг Grafana (`[database]`) и указать новый DSN;  
- перезапустить Grafana и проверить, что дашборды/пользователи/алерты на месте.

## Бэкапы и восстановление

Для восстановления Grafana после аварии нужно иметь под рукой:

- бэкап БД Grafana;  
- файлы конфигурации (`grafana.ini`, env‑файлы, `values.yaml`);  
- provisioning‑файлы и JSON‑дашборды (если они хранятся на диске, а не только в БД).

Процесс восстановления:

1. Развернуть новую инсталляцию Grafana нужной версии.  
2. Восстановить БД из бэкапа.  
3. Вернуть конфиг и provisioning‑файлы.  
4. Перезапустить и проверить доступ.

## Production‑аспекты: безопасность и наблюдаемость Grafana

### Безопасность

Минмальный чек‑лист:

- поменять дефолтный логин/пароль администратора;  
- включить HTTPS (через reverse‑proxy или встроенный TLS);  
- ограничить анонимный доступ к дашбордам (или чётко понимать, какие дашборды доступны анонимно);  
- по возможности интегрировать единую аутентификацию (OAuth2, SSO, LDAP и т.д.).

Также стоит аккуратно относиться к публичным ссылкам/снапшотам дашбордов, чтобы не утекли чувствительные данные.

### Наблюдаемость самой Grafana

Grafana — тоже сервис, и его нужно мониторить:

- включить экспорт внутренних метрик (обычно есть endpoint для Prometheus);  
- следить за ошибками запросов к datasource’ам, временем ответа, нагрузкой на БД;  
- иметь дашборд «здоровья Grafana», чтобы понимать, если она стала узким местом.
