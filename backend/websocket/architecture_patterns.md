# WebSocket: архитектура, масштабирование и кейсы

## 1. Архитектура WebSocket‑сервера

### Где размещать WebSocket‑сервер

В простейшем варианте WebSocket‑сервер — это отдельный сервис, который принимает постоянные соединения от клиентов и рассылает им события.
Чаще всего его ставят за L4/L7‑балансировщиком (Nginx/HAProxy/Ingress в Kubernetes), который раздаёт трафик по нескольким инстансам WS‑сервиса.

Есть два популярных подхода:

- Отдельный **WS‑gateway**: сервис реального времени, который почти не содержит бизнес‑логики, а только управляет соединениями и маршрутизирует события в/из других сервисов.
- «Толстый» бэкенд: обычный API‑сервис, который одновременно умеет REST/gRPC и WebSocket, что упрощает деплой, но усложняет масштабирование и обновления.

### Взаимодействие с остальными сервисами

WebSocket‑сервер не обязан содержать всю бизнес‑логику. Частая схема:

- WS‑сервер принимает события от клиента (например, «отправить сообщение в чат»).
- Проксирует их в «обычные» бэкенды по REST/gRPC/async‑шине.
- Получает от них результат/события и пушит их в нужные соединения.

Такой подход:

- Позволяет переиспользовать существующие микросервисы.
- Делает WebSocket‑слой «тонким» и относительно простым: он отвечает за коннекты, авторизацию и маршрутизацию сообщений.

---

## 2. Event‑driven подход и брокеры

### Событийная модель

WebSocket очень органично ложится на event‑driven архитектуру:

- Клиент отправляет не «RPC‑запросы», а события (например, `chat.message.send`).
- Бэкенды публикуют доменные события (`OrderCreated`, `PositionUpdated`), а WS‑слой подписывается и пушит их подписчикам.

Это даёт:

- Декуплинг между фронтом и отдельными микросервисами.
- Возможность подключать дополнительные консьюмеры (например, для аналитики или алертов), не трогая фронт/WS.

### Брокеры: Kafka, RabbitMQ, Redis Pub/Sub

Типовая схема:

- WS‑сервер **подписан** на топики/очереди брокера и получает оттуда события.
- При обновлениях от одного клиента WS‑сервер публикует события в брокер, а другие WS‑узлы получают их и пушат своим клиентам.

Зачем это нужно:

- Централизованный fan‑out: один доменный эвент попадает во все WS‑узлы через брокер.
- Устойчивость к падению одного узла: пока брокер жив, другие узлы продолжат рассылать события.

Выбор инструмента:

- **Redis Pub/Sub / Redis Streams** — просто, быстро, хорошо для небольших/средних нагрузок и географически близких узлов.
- **Kafka** — когда нужна устойчивость, репликация, порядковость и возможность реплея событий.
- **RabbitMQ / NATS** — когда важен гибкий роутинг, подтверждения доставки, различные модели подписок.

---

## 3. Масштабирование и High Availability

### Горизонтальное масштабирование

Ключевые моменты:

- Под WebSocket каждый инстанс держит тысячи–десятки тысяч долгоживущих соединений.
- При горизонтальном масштабировании добавляются/убираются инстансы WS‑сервера, а балансировщик распределяет новые подключения.

Трудности:

- Соединение «прилипает» к конкретному инстансу: нельзя свободно перекинуть существующий сокет на другой сервер.
- Fan‑out по нескольким инстансам требует общего канала (брокера или общей in‑memory/cluster‑инфраструктуры).

### Sticky‑sessions

Чтобы избежать постоянного переподключения клиентов:

- Балансировщик настраивается на **sticky‑sessions** (по cookie, IP hash или другому ключу), чтобы один и тот же клиент попадал на один и тот же инстанс.
- Это особенно важно для stateful‑логики (комнаты, приватные сессии, локальные кеши прав/профилей).

Но:

- Sticky‑sessions упрощают жизнь, но ухудшают равномерное распределение нагрузки.
- При сильной асимметрии клиентов (несколько «тяжёлых» клиентов) может потребоваться дополнительная логика распределения.

### Шардирование по пользователям/комнатам

Для крупных систем (биржи, крупные игры, соцсети) используют **логическое шардирование**:

- Шард по userID (например, hash(userID) % N) — каждый шард обслуживает подмножество пользователей.
- Шард по roomID — все участники комнаты попадают на один/ограниченный набор инстансов или шардов.

Цели:

- Локализовать горячие данные (комнаты, популярные каналы) на ограниченном числе машин.
- Облегчить кеширование и уменьшить объём межшардовой коммуникации.

### Pub/Sub‑слой и backpressure

Pub/Sub‑слой (Redis/Kafka/NATS) нужен, чтобы:

- Каждый WS‑инстанс мог рассылать события своим клиентам, но получать их со всех источников.
- Избежать «полной сетки» соединений между всеми инстансами.

Backpressure:

- Клиент может не успевать читать сообщения.
- На сервере нужно ограничивать размер очереди исходящих сообщений для каждого соединения и/или применять drop/сжатие/агрегацию.
- При переполнении очереди — закрывать соединение с понятной причиной и давать клиенту возможность корректного реконнекта.

### Наблюдаемость и мониторинг нагрузки

Критичные метрики:

- Количество открытых соединений по инстансам/шардам.
- RPS входящих/исходящих сообщений, средний размер сообщений.
- Очереди в брокере: лаг подписчиков, размер/скорость.
- Ошибки: rate disconnect’ов, ошибки апгрейда, таймауты ping/pong.

Практически всегда полезно:

- Вводить технические лимиты (макс. коннектов на инстанс/пользователя/IP).
- Иметь дешёвую health‑проверку и отдельные дашборды для real‑time слоя.

---

## 4. Типичные use‑cases WebSocket

### Чаты и мессенджеры

- Отправка/получение сообщений в реальном времени, статус «печатает», индикаторы онлайн/офлайн.
- Комнаты/каналы — естественный сценарий для шардирования и использования pub/sub‑слоя.

### Торговля и биржи

- Трансляция котировок, ордербуков, сделок с минимальной задержкой.
- Часто комбинируется с REST‑API: REST для запросов (создать ордер), WS для стриминга рынка и статуса ордеров.

### Игровые серверы

- Real‑time взаимодействие игроков: позиции, действия, события матча.
- Важно контролировать размер и частоту сообщений, использовать UDP/кастомные протоколы там, где важна ещё более низкая задержка.

### Уведомления и live‑обновления

- Уведомления о новых событиях: комментарии, лайки, статусы задач, системные алерты.
- Подходит для большинства «социальных» и бизнес‑приложений, где пользователю важно видеть изменения без перезагрузки страницы.

### Совместное редактирование и трекинг позиций

- Реальный‑тайм редактирование документов (Google Docs‑подобные сценарии), курсоры других пользователей, версии.
- Трекинг позиций: карты курьеров/водителей, геолокация сотрудников/объектов, логистика и мониторинг.

Во всех этих кейсах WebSocket обычно выступает как транспорт для событийной модели: система генерирует доменные события, а WS‑слой эффективно доставляет их нужным клиентам в реальном времени.
