# gRPC observability

> Observability для gRPC‑сервисов = умение ответить на вопросы «что происходит?», «где болит?» и «почему?» по логам, метрикам и трейсам, не залезая в код и не поднимая локально весь зоопарк.

---

## Зачем нужна observability в gRPC

gRPC быстрый и бинарный: «на глаз» и через curl уже не посмотришь, что прилетает и откуда прилетела ошибка.  
Поэтому важно с самого начала закладывать логи, метрики и распределённый трейсинг в протокол взаимодействия сервисов и в инфраструктуру вокруг них.

Основные цели:

- понимать латентность и ошибки на уровне RPC‑методов;
- видеть, как запрос «протекает» через микросервисы;
- быстро находить деградации и регрессии в проде.

---

## Три кита: логи, метрики, трейсы

Классическое разделение:

- **Логи**  
  Детальный контекст конкретного события: входные данные (частично), идентификаторы, сообщения об ошибках, debug‑инфо.  
  Логи хороши для «разборов полётов» по единичным кейсам.

- **Метрики**  
  Агрегированные числовые показатели: RPS, latency, error rate, размер payload’ов, количество активных стримов.  
  Метрики отвечают на вопрос «что в среднем/в целом происходит с системой».

- **Трейсы (distributed tracing)**  
  Цепочка спанов, которая показывает путь одного запроса через несколько сервисов: клиент → API → сервис A → сервис B → БД и т.п.  
  Трейсы помогают найти, где в цепочке запросов прячется узкое место или ошибка.

---

## Где «подцепиться» в gRPC

gRPC идеально «ложится» на концепцию **интерсепторов**:

- **server‑side interceptors**:
    - логирование входящих запросов и исходящих ответов;
    - снятие метрик по каждому RPC;
    - создание/замыкание трейс‑спанов;
- **client‑side interceptors**:
    - логирование исходящих RPC‑вызовов;
    - метрики клиента (особенно для критичных зависимостей);
    - продолжение trace‑контекста.

Идея: не размазывать observability по бизнес‑коду, а подключать её на «границе» — там, где запрос входит и выходит из gRPC.

---

## Какие метрики снимать с gRPC

Минимальный набор:

- **RPS / calls**:
    - количество вызовов по методу (`grpc_server_requests_total{method="UserService/GetUser"}`);
- **latency**:
    - гистограммы/summary по времени выполнения RPC;
    - желательно с лейблами по методу и статус‑коду;
- **error rate**:
    - количество ошибок по `codes.*` (NotFound, Unavailable, DeadlineExceeded, Internal…);
- **payload size**:
    - размер запросов/ответов (особенно важно для стриминга и больших сообщений).

Полезные лейблы/теги:

- `grpc.service`, `grpc.method`;
- `grpc.code` (OK, NotFound, Unavailable…);
- `peer.address` (иногда).

---

## Трейсинг и контекст в gRPC

Для распределённого трейсинга обычно используют OpenTelemetry:

- **На клиенте**:
    - перед RPC создаётся или извлекается span из текущего контекста;
    - trace‑контекст (trace id, span id, baggage) прокидывается в gRPC‑метаданные;
- **На сервере**:
    - из метаданных извлекается контекст;
    - создаётся новый span, «дочерний» от клиентского;
    - внутренняя логика сервиса (вызовы БД/кэша/других сервисов) тоже оборачивается в спаны.

Важно:

- каждый RPC‑вызов = хотя бы один span (client‑side / server‑side);
- trace id должен быть одинаковым по всей цепочке вызова;
- в spans стоит записывать ключевые атрибуты: `rpc.system="grpc"`, `rpc.service`, `rpc.method`, `net.peer.*`, `error`/`status.code`.

---

## Логирование: что логировать для gRPC

Базовый минимум:

- метод (`/package.Service/Method`);
- статус (успех/код ошибки);
- latency (ms);
- идентификаторы (trace id, user id, request id);
- ключевые аргументы (сильно обрезанные/обезличенные, без чувствительных данных).

Типичный паттерн:

- **в интерсепторе**:
    - на входе — логировать «call started» в debug/trace (опционально);
    - на выходе — логировать «call finished»: метод, код, latency, ids.

Не стоит:

- писать в логи весь payload целиком (особенно в проде);
- логировать токены/пароли/PII.

---

## OpenTelemetry / Prometheus / прочие инструменты

В Go‑мире часто комбинация такая:

- **Prometheus**:
    - метрики через экспортер (`promhttp` на отдельном HTTP‑эндпоинте);
    - gRPC‑interceptor, который обновляет счётчики/гистограммы.
- **OpenTelemetry**:
    - трассировка (`otelgrpc` интерсепторы для клиента и сервера);
    - метрики и логи при необходимости;
    - экспорт в Jaeger/Tempo/OTLP‑совместимый бэкенд.
- **Логгер**:
    - structured logging (`zap`, `zerolog`, `logrus` и т.п.);
    - интеграция через интерсепторы.

Смысл: gRPC‑слой даёт точки входа, OpenTelemetry — универсальный стандарт, а дальше уже выбор бэкенда (Jaeger, Tempo, Grafana, Datadog, etc.).

---

## Пример: observability‑стек вокруг gRPC

Очень коротко, как это может выглядеть концептуально:

- **На gRPC‑сервере**:
    - chain unary interceptor:
        - tracing (OpenTelemetry),
        - metrics (Prometheus),
        - logging (structured).
- **На gRPC‑клиенте**:
    - такие же interceptors для исходящих вызовов.

В итоге для каждого RPC в системе есть:

- запись в логах (или хотя бы для ошибок);
- метрики по методу и коду;
- trace‑спан, по которому можно увидеть путь запроса через все сервисы.

---

## Практические рекомендации

Краткий чек‑лист:

- включать observability **сразу**, а не «потом»;
- не плодить формат логов — один формат, один логгер, единый кореляционный id;
- не считать «всё подряд» — думать, какие метрики реально нужны;
- не забывать про gRPC‑специфику:
    - коды ошибок (`codes.*`);
    - особенности стриминга (длинные живые RPC);
    - размер сообщений и регулярные пики.